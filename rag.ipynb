{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a2f028-b2ad-49f7-bc03-78a87222430e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Part 1: Chunk Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6f4656-ce5f-416d-a61e-2871a4b50596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# NOTE: assume manually separated by THREE newlines already\n",
    "loader = DirectoryLoader('data/rag', glob='**/*text.txt', loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "# with open(\"data/rag/gene_query_docs.txt\", \"r\") as doc_fd:\n",
    "#     ref_text = doc_fd.read().split(\"\\n\\n\\n\")\n",
    "#     ref_text = list(map(lambda s: s.strip(), ref_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda51232-72a9-4bf8-98b1-ed5c59ac5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\\n\", chunk_size=1, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035df40-0a56-4600-9628-91bed179212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[2].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91031495-d5ec-401f-b723-8409c68f6806",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Part 2: Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbe416-ab68-43e0-8608-ad3d57124320",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "class CustomHuggingFaceEmbeddings(Embeddings):\n",
    "    def __init__(self, model, tokenizer, device=None):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device if device else torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        return [self._embed(text) for text in texts]\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return self._embed(text)\n",
    "    \n",
    "    def _embed(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            # Assuming you want to use the mean pooling of the last hidden state\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc784d93-ba56-4421-b1c3-9064aa4d1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# using a reasonable model from https://huggingface.co/spaces/mteb/leaderboard\n",
    "embedding_model_name = 'Snowflake/snowflake-arctic-embed-l'\n",
    "model_kwargs = {\"device\": \"cuda:1\"}\n",
    "\n",
    "# Load custom tokenizer and model if needed\n",
    "# add pad token - https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/\n",
    "# tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "# tokenizer.add_special_tokens({'pad_token': '<|finetune_right_pad_id|>'})\n",
    "# model = AutoModel.from_pretrained(embedding_model_name, torch_dtype=torch.float32).to(\"cuda:1\")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name, model_kwargs=model_kwargs)\n",
    "# embeddings = CustomHuggingFaceEmbeddings(model=model, tokenizer=tokenizer, device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31090e-e0c2-4eca-bcd2-bc14d0a13e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Set up the vector store\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "vectorstore.save_local(folder_path=\"data/rag\", index_name=\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e405a3-17e1-4970-9dac-a1d2b4ba222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(folder_path=\"data/rag\", index_name=\"faiss_index\", embeddings=embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f797f3e1-e7ed-4700-8764-706b1ab407c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 16})\n",
    "out = retriever.batch([\"give me uniprot id of the gene with the entrez gene id of 1017\", \"What are the symbol and Ensembl gene ID for genes in species 9669 with a symbol starting with 'LOC123388108'?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "985b885e-352d-44db-a1ad-fd5240954db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content=\"entrezgene - This field contains a string representing the unique identifier assigned by NCBI's Entrez Gene database. It is used to uniquely identify genes in this centralized resource.\"),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='ensembl.gene - The Ensembl identifier for the gene, which is a unique reference used to describe the gene in the Ensembl database.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='reagent.GNF_mm-kinase_lenti-shRNA.id - Unique identifier for a lentiviral shRNA reagent targeting mouse kinase genes in the GNF library.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='genomic_pos_mm9.chr - The chromosome number for the gene using the mouse genome assembly version mm9.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='SGD - A unique identifier from the Saccharomyces Genome Database, which provides genomic information on the budding yeast, Saccharomyces cerevisiae.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='reporter.GNF1H - This field contains an identifier for a probe set used in the GNF1H microarray platform, which is associated with gene expression profiling.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='biocarta - This field contains text data referencing pathways or identifiers in BioCarta, which offers information on biological pathways and systems.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='reporter.EquGene-1_0 - This field contains an identifier for a probe set used in the EquGene-1_0 microarray platform.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='ensembl.protein - This field contains an array of strings representing the unique Ensembl stable identifiers for protein sequences associated with a gene. These identifiers help in tracking protein isoforms corresponding to specific transcription events.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='name - The primary name of the gene or protein as recognized in scientific databases.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='reporter.GuiGene-1_0 - This field contains an identifier for a probe set used in the GuiGene-1_0 microarray platform.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='alias - This field is a keyword that provides alternative names or symbols commonly used to refer to the gene or feature.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content=\"pantherdb.ortholog.GeneID - This field includes ortholog identifiers as represented by GeneID, a unique identifier for genes in NCBI's Entrez Gene database.\"),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='reporter.GNF1M - This field contains an identifier for a probe set used in the GNF1M microarray platform, which is associated with gene expression profiling.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='genomic_pos.chr - The chromosome number on which the gene is located, specified as a keyword or string.'),\n",
       " Document(metadata={'source': 'data/rag/compact_desc_with_context.txt'}, page_content='genomic_pos_hg19.chr - The chromosome number for the gene using the human genome assembly version GRCh37/hg19.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600bd1c-eaa6-4f0a-bd3a-0f8ceec95636",
   "metadata": {},
   "source": [
    "# Part 3: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60a703-eb27-423d-bcd7-6c08b175cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines\n",
    "\n",
    "@outlines.prompt\n",
    "def rag_prompt(instruction, relevant_docs):\n",
    "    \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Use the documentation to complete the user-given task.\n",
    "Docs: {{ relevant_docs }}\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "{{ instruction }}. Write an API call.\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca043195-dbcd-40a4-bdfb-61e8fefc3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_retrieved_docs(doc_batches):\n",
    "    return [\"\\n\\n\".join([doc.page_content for doc in doc_batch]) for doc_batch in doc_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7b56d-48b8-433b-a9cd-627aea07b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(starmap(lambda x, y, z: (x, y, z), [1,2,3], [4], [5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e4973-db71-40ce-80ad-e290ff329c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d507e81-87cc-430a-86e2-efbb64c62faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "        return_full_text=False,\n",
    "    ),\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520aca6a-5615-4f45-aa00-c215f84f2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(\n",
    "        content=\"What happens when an unstoppable force meets an immovable object?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "ai_msg = chat_model.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
