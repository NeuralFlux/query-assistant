{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4170e02d-cfc6-4e00-9424-2305c4761b55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Part 1: Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cde1a5-c0cd-483b-9fd6-8967a5dfea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def parse_url(url):\n",
    "    \"\"\"\n",
    "    Parse a URL into its components.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    return {\n",
    "        'path': parsed_url.path,\n",
    "        'params': query_params\n",
    "    }\n",
    "\n",
    "def is_url_structure_matching(candidate, reference):\n",
    "    \"\"\"\n",
    "    Compare the path and query parameters of the candidate and reference URLs.\n",
    "    \"\"\"\n",
    "    if candidate['path'] != reference['path']:\n",
    "        return False\n",
    "\n",
    "    if sorted(candidate['params'].keys()) != sorted(reference['params'].keys()):\n",
    "        return False\n",
    "\n",
    "    for key in reference['params']:\n",
    "        if key not in candidate['params']:\n",
    "            return False\n",
    "        if sorted(candidate['params'][key]) != sorted(reference['params'][key]):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def evaluate_get_request_accuracy(generated_url, reference_url):\n",
    "    \"\"\"\n",
    "    Evaluate if the generated GET request is equivalent to the reference GET request.\n",
    "    \"\"\"\n",
    "    candidate = parse_url(generated_url)\n",
    "    reference = parse_url(reference_url)\n",
    "    \n",
    "    return is_url_structure_matching(candidate, reference)\n",
    "\n",
    "def score_ast_batched(preds, refs):\n",
    "    evals = tuple(map(evaluate_get_request_accuracy, preds, refs))\n",
    "    return sum(evals) / len(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f043053-044d-4790-86c8-7d075491c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "bert_scorer = evaluate.load(\"bertscore\")\n",
    "bert_score_fn = lambda preds, refs: bert_scorer.compute(predictions=preds, references=refs, lang=\"en\", model_type=\"microsoft/codebert-base\", num_layers=12, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27685061-e162-4362-ad4a-bc8bd1989ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\"/v3/query/?q=symbol:ZFAND4&species=mouse\"]\n",
    "refs = [\"/v3/query/?species=mouse&q=symbol:ZFAND4\"]\n",
    "\n",
    "print(\"AST eval\", score_ast_batched(preds, refs))\n",
    "print(\"BERT Score\", bert_score_fn(preds, refs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c95b9f4-c60b-45be-a974-9d28e62c0324",
   "metadata": {},
   "source": [
    "## Part 2: Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01242a88-8ebf-41a7-9668-5c6fd59b39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92578b0d-2abe-49a4-b95c-48656531a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gene_query_docs.txt\", \"r\") as doc_fd:\n",
    "    docs = doc_fd.read()\n",
    "\n",
    "with open(\"data/original/compact_desc_with_context.csv\") as desc_fd:\n",
    "    description = desc_fd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c658b-cf58-4695-b1bd-41b6050eb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "prompt_template = inspect.cleandoc(\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "Use the documentation and schema to complete the user-given task.\n",
    "Docs: {docs}\\n Schema: {description}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "{instruction}. Write an API call.\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce25b3a-cbb0-45f0-9ac7-d8e61733a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_gen = lambda inst: prompt_template.format(docs=docs, description=description, instruction=inst)\n",
    "prompt = prompt_gen(\"Find the UniProt ID for the ENSG00000103187 gene in human. Limit the search to Ensembl gene IDs.\")\n",
    "print(\"Start\", prompt[:250])\n",
    "print(\"End\", prompt[-150:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0e0cfd-8de2-49f2-9784-213157f2554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"models/meta_llama3_1\", torch_dtype=torch.bfloat16, output_attentions=True).to(\"cuda\")\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"models/meta_llama3_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4593a22-328c-4769-a3b8-86f693f4c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(api_call: str):\n",
    "    return None\n",
    "\n",
    "model = outlines.models.Transformers(model, tokenizer)\n",
    "generator = outlines.generate.json(model, evaluate)\n",
    "# generator = outlines.generate.regex(model, r\"/v3/.+/.+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e069e8-169a-4ab5-ad4e-f27e1279d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_api_call = generator([prompt])\n",
    "sample_api_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eeb61e-9610-4151-9dae-31d80e38e1c6",
   "metadata": {},
   "source": [
    "## Part 3: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f23aa-dc0b-4619-8c14-6ed5de46d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"moltres23/biothings-query-instruction-pairs\", split=\"test\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d149896-f8b4-4ce7-a331-62b297736851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "all_responses = []\n",
    "prompt_gen = lambda inst: prompt_template.format(docs=docs, description=description, instruction=inst)\n",
    "with torch.no_grad():\n",
    "    for idx in tqdm.tqdm(range(0, len(dataset), BATCH_SIZE)):\n",
    "        batch = dataset[idx:(idx + BATCH_SIZE)]\n",
    "        batched_inputs = list(map(prompt_gen, batch[\"instruction\"]))\n",
    "        batch_responses = generator(batched_inputs)\n",
    "        all_responses.extend(batch_responses.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb751d57-cc00-4e49-9258-2db322722421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44e8fd-4c1a-44fd-be06-5e61c2dc0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('responses.pkl', 'wb') as fd:\n",
    "   pickle.dump(all_responses, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31e964-55fb-40c1-be1a-6bdabddd3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('responses.pkl', 'rb') as fd:\n",
    "   all_responses = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac670ef-ae9a-4a0e-8c8e-956fa019b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def regex_match(string):\n",
    "    match = re.search(r\"/v3/.+\", string)\n",
    "    return match.group(0) if match is not None else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c8665-3dc5-47a4-875b-7dd320df4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_match(\"GET https://mygene.infov3/query?fields=human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91358fa-b49c-4ed0-8ddc-70e7252bacd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_responses = list(map(lambda x: regex_match(x), all_responses))\n",
    "ast_eval = score_ast_batched(all_responses, dataset[\"output\"])\n",
    "bertscore_evals = bert_score_fn(all_responses, dataset[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a29962-bff4-4730-9bc3-2d6cd1e8609a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "# we include 0s in mean because otherwise merely getting\n",
    "# one correct answer will skew the metric\n",
    "print(\"AST eval\", ast_eval)\n",
    "print(\"BERT Score\", np.mean(bertscore_evals[\"recall\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0e2f4-89d2-4388-bfd1-d83bb1eb28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3017f-68dd-48c9-b548-7dd203d4c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"output\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff706223-49a6-4a36-84df-bc434bc4723d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
